{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/share/Real/KAIST/700G_new\n"
     ]
    }
   ],
   "source": [
    "%cd /root/share/Real/KAIST/700G_new/\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/VLL-HD/FrEIA.git\n",
      "  Cloning https://github.com/VLL-HD/FrEIA.git to /tmp/pip-req-build-umfh2kxm\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/VLL-HD/FrEIA.git /tmp/pip-req-build-umfh2kxm\n",
      "  Resolved https://github.com/VLL-HD/FrEIA.git to commit a4d3a7db135460e4dd11d4fd7f24b1c97fe7c0d3\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: pytorch-ignite==0.4.2 in /opt/conda/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: torch<2,>=1.3 in /opt/conda/lib/python3.10/site-packages (from pytorch-ignite==0.4.2) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from FrEIA==0.2) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5 in /opt/conda/lib/python3.10/site-packages (from FrEIA==0.2) (1.10.1)\n",
      "Requirement already satisfied: graphviz>=0.20.1 in /opt/conda/lib/python3.10/site-packages (from FrEIA==0.2) (0.20.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (66.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.54.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.29.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.38.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (4.23.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.4.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.18.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.3.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.26.15)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2023.5.7)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch<2,>=1.3->pytorch-ignite==0.4.2) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch<2,>=1.3->pytorch-ignite==0.4.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch<2,>=1.3->pytorch-ignite==0.4.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch<2,>=1.3->pytorch-ignite==0.4.2) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch<2,>=1.3->pytorch-ignite==0.4.2) (8.5.0.96)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/VLL-HD/FrEIA.git tensorboard pytorch-ignite==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import model_flow\n",
    "import constant as const\n",
    "import utils\n",
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.set_config(transform_output=\"pandas\") #python version >= 3.8, sklearn version >= 1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_seeds(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(disease_no, test_size=0.2):\n",
    "\n",
    "    df = pd.read_csv(\"Data/phr_data_dropped.csv\")\n",
    "    target_variables = {\n",
    "        0 : ['bmi', 'height', 'weight', 'waist'],\n",
    "        1 : ['blood_sugar'],\n",
    "        2 : ['neutral_fat'],\n",
    "        3 : ['hdl', 'ldl'], #neutral fat and choloesterol are controversial\n",
    "        4 : ['got', 'gpt'], #gamma gtp\n",
    "        5 : ['hemoglobin'],\n",
    "        6 : ['max_bp', 'min_bp']\n",
    "    }\n",
    "\n",
    "    #Dropping NA values in target variables\n",
    "    df.dropna(subset = target_variables[disease_no], inplace=True)\n",
    "\n",
    "    #Dropping genetic features\n",
    "    df = df.drop(df.columns[:64], axis=1)\n",
    "\n",
    "    criterion = {\n",
    "        0: df['bmi']>=25,\n",
    "        1: df['blood_sugar']>=126,\n",
    "        2: df['neutral_fat']>=np.log1p(200),\n",
    "        3: (df['hdl']<40)|(df['ldl']>=160),\n",
    "        4: (df['got']>np.log1p(40))|(df['gpt']>np.log1p(40)),\n",
    "        5: df['hemoglobin']+df['gender']<=13, #modified from <13\n",
    "        6: (df['max_bp']>=130)|(df['min_bp']>=80)\n",
    "    }\n",
    "\n",
    "    diseases = np.where(criterion[disease_no], 1, 0)\n",
    "    diseases = pd.Series(diseases, index=df.index)\n",
    "\n",
    "    #Leaving lifelog and servey.etc\n",
    "    #df = df[df.columns[19:].append(pd.Index(target_variables[disease_no]))]\n",
    "    \n",
    "    x = df.copy()\n",
    "    x.drop(columns=target_variables[disease_no], axis=1, inplace=True)\n",
    "\n",
    "    diseases = np.where(criterion[disease_no], 1, 0)\n",
    "    encoder = LabelEncoder()\n",
    "    diseases = encoder.fit_transform(diseases)\n",
    "\n",
    "    normal = df[diseases == 0]\n",
    "    diseases = df[diseases == 1] \n",
    "    x_diseases = diseases.drop(columns=target_variables[disease_no], axis=1)\n",
    "    y_diseases = pd.DataFrame(np.ones(len(x_diseases)), columns=['diseases'], index=x_diseases.index)\n",
    "    x_normal = normal.drop(columns=target_variables[disease_no], axis=1)\n",
    "    y_normal = pd.DataFrame(np.zeros(len(x_normal)), columns=['diseases'], index=x_normal.index)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_normal, y_normal, test_size=1-const.TRAIN_RATIO, stratify=normal['gender'])\n",
    "    \n",
    "    x_test = pd.concat([x_test, x_diseases])\n",
    "    y_test = pd.concat([y_test, y_diseases])\n",
    "\n",
    "    #Conditions are not scaled.\n",
    "    con_vec = [\"age\", \"gender\"]\n",
    "    \n",
    "    c_train = x_train[con_vec]\n",
    "    c_test = x_test[con_vec]\n",
    "\n",
    "    x_train.drop(con_vec, axis=1, inplace=True)\n",
    "    x_test.drop(con_vec, axis=1, inplace=True)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, c_train, c_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline():\n",
    "    pca_for_features = ColumnTransformer([\n",
    "        ('pca_smoking_all', PCA(n_components=1), ['have_smoking', 'smoking_duration_all', 'smoking_all_count']),\n",
    "        ('pca_secondary_smoking_home', PCA(n_components=1), ['secondary_smoking_home', 'secondary_smoking_home_count_per_week', 'secondary_smoking_duration_home', 'secondary_smoking_hour_home']),\n",
    "        ('pca_secondary_smoking_work', PCA(n_components=1), ['secondary_smoking_work', 'secondary_smoking_work_per_week', 'secondary_smoking_duration_work', 'secondary_smoking_hour_work']),\n",
    "        ('pca_recent_symptom', PCA(n_components=2), ['last2week_symptom_decreasedintertest_in_last2weeks', 'last2week_symptom_depressed_in_last2weeks',\n",
    "                                                    'last2week_symptom_sleepdisorder_in_last2weeks', 'last2week_symptom_tiredness_in_last2weeks',\n",
    "                                                    'last2week_symptom_eatingdisorder_in_last2weeks', 'last2week_symptom_discourage_in_last2weeks',\n",
    "                                                    'last2week_symptom_decreasedconcentration_in_last2weeks', 'last2week_symptom_anxious_in_last2weeks',\n",
    "                                                    'last2week_symptom_selfharm_in_last2weeks'])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    preproc_pipeline = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('imputer', IterativeImputer()),\n",
    "        ('pca_for_smoking', pca_for_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return preproc_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num, random_state):\n",
    "    init_seeds(random_state)\n",
    "    num = num\n",
    "\n",
    "    x_train, x_test, y_train, y_test, c_train, c_test = load_dataset(disease_no=num)\n",
    "\n",
    "    preproc_pipeline = build_pipeline()\n",
    "    x_train = preproc_pipeline.fit_transform(x_train)\n",
    "    x_test = preproc_pipeline.transform(x_test)\n",
    "    \n",
    "    x_train = torch.FloatTensor(x_train.values).to('cuda')\n",
    "    #y_train = torch.tensor(y_train.values).to(\"cuda\")\n",
    "    c_train = torch.FloatTensor(c_train.values).to('cuda')\n",
    "    x_test = torch.FloatTensor(x_test.values).to('cuda')\n",
    "    #y_test = torch.tensor(y_test)\n",
    "    c_test = torch.FloatTensor(c_test.values).to('cuda')\n",
    "\n",
    "    model = model_flow.CD_Flow(\n",
    "        dim_features = x_train.shape[1],\n",
    "        flow_steps = const.FLOW_STEPS,\n",
    "        cond_dims = 2\n",
    "    ).to('cuda')\n",
    "\n",
    "    main.train(model, x_train, x_test, y_test, c_train, c_test, multiple = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------RANDOM STATE: 42 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "2023-05-25 18:30:21,367 eval INFO: [epoch 0] [AUROC 0.8298284449363594] [AUPRC 0.08810499277578981]\n",
      "2023-05-25 18:30:22,875 eval INFO: [epoch 1] [AUROC 0.817653569452131] [AUPRC 0.08085667301109026]\n",
      "2023-05-25 18:30:24,383 eval INFO: [epoch 2] [AUROC 0.8049252905368011] [AUPRC 0.07541374264849963]\n",
      "2023-05-25 18:30:25,876 eval INFO: [epoch 3] [AUROC 0.794133923630327] [AUPRC 0.0703175108607919]\n",
      "2023-05-25 18:30:27,376 eval INFO: [epoch 4] [AUROC 0.7866629773104593] [AUPRC 0.06786533564942676]\n",
      "2023-05-25 18:30:28,876 eval INFO: [epoch 5] [AUROC 0.7899833978970666] [AUPRC 0.06844387111358076]\n",
      "2023-05-25 18:30:30,401 eval INFO: [epoch 6] [AUROC 0.7921970116214719] [AUPRC 0.06874731391239597]\n",
      "2023-05-25 18:30:31,912 eval INFO: [epoch 7] [AUROC 0.7960708356391809] [AUPRC 0.06991917081036776]\n",
      "2023-05-25 18:30:33,418 eval INFO: [epoch 8] [AUROC 0.796624239070282] [AUPRC 0.06995644899160598]\n",
      "2023-05-25 18:30:34,923 eval INFO: [epoch 9] [AUROC 0.7971776425013832] [AUPRC 0.07031031889082964]\n",
      "2023-05-25 18:30:36,439 eval INFO: [epoch 10] [AUROC 0.7982844493635861] [AUPRC 0.07061383294428263]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m ran \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m42\u001b[39m, \u001b[39m92\u001b[39m): \u001b[39m#42, 43 .... , 51\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m------RANDOM STATE:\u001b[39m\u001b[39m\"\u001b[39m, ran, \u001b[39m\"\u001b[39m\u001b[39m------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     train(\u001b[39m1\u001b[39;49m, ran)\n",
      "Cell \u001b[0;32mIn[29], line 24\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num, random_state)\u001b[0m\n\u001b[1;32m     16\u001b[0m c_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(c_test\u001b[39m.\u001b[39mvalues)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m model \u001b[39m=\u001b[39m model_flow\u001b[39m.\u001b[39mCD_Flow(\n\u001b[1;32m     19\u001b[0m     dim_features \u001b[39m=\u001b[39m x_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[1;32m     20\u001b[0m     flow_steps \u001b[39m=\u001b[39m const\u001b[39m.\u001b[39mFLOW_STEPS,\n\u001b[1;32m     21\u001b[0m     cond_dims \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     22\u001b[0m )\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m main\u001b[39m.\u001b[39;49mtrain(model, x_train, x_test, y_test, c_train, c_test, multiple \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/share/Real/KAIST/700G_new/Scripts/Flow_zero/main.py:56\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, x_train, x_test, y_test, c_train, c_test, multiple)\u001b[0m\n\u001b[1;32m     54\u001b[0m train_one_epoch(model, x_train, c_train, epoch, optimizer, optimizer_altub, scheduler, tb_logger)\n\u001b[1;32m     55\u001b[0m \u001b[39mif\u001b[39;00m (epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m const\u001b[39m.\u001b[39mEVAL_EPOCH \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m     test_one_epoch(model, x_test, y_test, c_test, epoch, tb_logger, eval_logger, multiple)\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m (epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m const\u001b[39m.\u001b[39mSAVE_EPOCH \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     58\u001b[0m     save_model(model, optimizer, scheduler, epoch, checkpoint_dir)\n",
      "File \u001b[0;32m~/share/Real/KAIST/700G_new/Scripts/Flow_zero/main.py:86\u001b[0m, in \u001b[0;36mtest_one_epoch\u001b[0;34m(model, x_test, y_test, c_test, epoch, tb_logger, eval_logger, multiple)\u001b[0m\n\u001b[1;32m     83\u001b[0m     pred \u001b[39m=\u001b[39m model(x_test, c_test)\n\u001b[1;32m     84\u001b[0m score \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(pred[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu())\n\u001b[0;32m---> 86\u001b[0m auroc, auprc \u001b[39m=\u001b[39m evaluate_with_ratio(y_test, score, multiple)\n\u001b[1;32m     88\u001b[0m eval_logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m] [AUROC \u001b[39m\u001b[39m{\u001b[39;00mauroc\u001b[39m}\u001b[39;00m\u001b[39m] [AUPRC \u001b[39m\u001b[39m{\u001b[39;00mauprc\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     89\u001b[0m tb_logger\u001b[39m.\u001b[39madd_scalar(\u001b[39m'\u001b[39m\u001b[39mAUROC\u001b[39m\u001b[39m'\u001b[39m, auroc, epoch)\n",
      "File \u001b[0;32m~/share/Real/KAIST/700G_new/Scripts/Flow_zero/main.py:112\u001b[0m, in \u001b[0;36mevaluate_with_ratio\u001b[0;34m(y_test, score, multiple)\u001b[0m\n\u001b[1;32m    110\u001b[0m     score_eval \u001b[39m=\u001b[39m score\u001b[39m.\u001b[39mdrop(drop_index)\n\u001b[1;32m    111\u001b[0m     y_test_eval \u001b[39m=\u001b[39m y_test\u001b[39m.\u001b[39mdrop(drop_index)\n\u001b[0;32m--> 112\u001b[0m     auroc_list\u001b[39m.\u001b[39mappend(roc_auc_score(y_test_eval, score_eval))\n\u001b[1;32m    113\u001b[0m     auprc_list\u001b[39m.\u001b[39mappend(average_precision_score(y_test_eval, score_eval))\n\u001b[1;32m    115\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(auroc_list)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(auroc_list), \u001b[39msum\u001b[39m(auprc_list)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(auprc_list)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:549\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_auc_score\u001b[39m(\n\u001b[1;32m    366\u001b[0m     y_true,\n\u001b[1;32m    367\u001b[0m     y_score,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m     labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    374\u001b[0m ):\n\u001b[1;32m    375\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \\\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[39m    from prediction scores.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39m    array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m     y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    550\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    551\u001b[0m     y_score \u001b[39m=\u001b[39m check_array(y_score, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/multiclass.py:329\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(y):\n\u001b[1;32m    328\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_y_kwargs)\n\u001b[1;32m    330\u001b[0m     \u001b[39mexcept\u001b[39;00m (np\u001b[39m.\u001b[39mVisibleDeprecationWarning, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    331\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(e)\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:825\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    822\u001b[0m context \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m estimator_name \u001b[39mif\u001b[39;00m estimator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39m# When all dataframe columns are sparse, convert to a sparse array\u001b[39;00m\n\u001b[0;32m--> 825\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(array, \u001b[39m\"\u001b[39;49m\u001b[39msparse\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    826\u001b[0m     \u001b[39mwith\u001b[39;00m suppress(\u001b[39mImportError\u001b[39;00m):\n\u001b[1;32m    827\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m is_sparse\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5982\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5983\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5984\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5985\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5986\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5987\u001b[0m ):\n\u001b[1;32m   5988\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[1;32m    225\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/arrays/sparse/accessor.py:31\u001b[0m, in \u001b[0;36mBaseAccessor.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent \u001b[39m=\u001b[39m data\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/arrays/sparse/accessor.py:232\u001b[0m, in \u001b[0;36mSparseFrameAccessor._validate\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m--> 232\u001b[0m     dtypes \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mdtypes\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(t, SparseDtype) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m dtypes):\n\u001b[1;32m    234\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validation_msg)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:6158\u001b[0m, in \u001b[0;36mNDFrame.dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6130\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   6131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdtypes\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   6132\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6133\u001b[0m \u001b[39m    Return the dtypes in the DataFrame.\u001b[39;00m\n\u001b[1;32m   6134\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6156\u001b[0m \u001b[39m    dtype: object\u001b[39;00m\n\u001b[1;32m   6157\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6158\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mget_dtypes()\n\u001b[1;32m   6159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_sliced(data, index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mobject_)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/managers.py:277\u001b[0m, in \u001b[0;36mBaseBlockManager.get_dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_dtypes\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     dtypes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray([blk\u001b[39m.\u001b[39;49mdtype \u001b[39mfor\u001b[39;49;00m blk \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks])\n\u001b[1;32m    278\u001b[0m     \u001b[39mreturn\u001b[39;00m dtypes\u001b[39m.\u001b[39mtake(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblknos)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree('_experiments')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for ran in range(42, 92): #42, 43 .... , 51\n",
    "    print(\"\\n\\n------RANDOM STATE:\", ran, \"------\")\n",
    "    train(1, ran)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

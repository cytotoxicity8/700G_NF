{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Real/KAIST/700G\n"
     ]
    }
   ],
   "source": [
    "%cd /root/Real/KAIST/700G/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (1.23.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (1.5.0)\n",
      "Collecting matplotlib==3.5.3\n",
      "  Downloading matplotlib-3.5.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in /opt/conda/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.8/site-packages (3.3.5)\n",
      "Requirement already satisfied: shap in /opt/conda/lib/python3.8/site-packages (0.41.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.3) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.3) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.3) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.3) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.3) (4.37.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.3) (1.4.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.8/site-packages (from scikit-learn==1.2.2) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn==1.2.2) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn==1.2.2) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.8/site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.8/site-packages (from shap) (2.2.0)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.8/site-packages (from shap) (0.56.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib==3.5.3) (1.16.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.8/site-packages (from numba->shap) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from numba->shap) (65.4.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.8/site-packages (from numba->shap) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata->numba->shap) (3.9.0)\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.6.0\n",
      "    Uninstalling matplotlib-3.6.0:\n",
      "      Successfully uninstalled matplotlib-3.6.0\n",
      "Successfully installed matplotlib-3.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas matplotlib==3.5.3 seaborn scikit-learn==1.2.2 lightgbm shap tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import shap\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.set_config(transform_output=\"pandas\") #python version >= 3.8, sklearn version >= 1.2.0\n",
    "LGBMClassifier.transform = lambda self,x:x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(disease_no, test_size=0.2):\n",
    "\n",
    "    df = pd.read_csv(\"Data/phr_data_dropped.csv\")\n",
    "    target_variables = {\n",
    "        0 : ['bmi', 'height', 'weight', 'waist'],\n",
    "        1 : ['blood_sugar'],\n",
    "        2 : ['neutral_fat'],\n",
    "        3 : ['hdl', 'ldl'], #neutral fat and choloesterol are controversial\n",
    "        4 : ['got', 'gpt'], #gamma gtp\n",
    "        5 : ['hemoglobin'],\n",
    "        6 : ['max_bp', 'min_bp']\n",
    "    }\n",
    "\n",
    "    #Dropping NA values in target variables\n",
    "    df.dropna(subset = target_variables[disease_no], inplace=True)\n",
    "\n",
    "    #Dropping genetic features\n",
    "    df = df.drop(df.columns[:64], axis=1)\n",
    "\n",
    "    criterion = {\n",
    "        0: df['bmi']>=25,\n",
    "        1: df['blood_sugar']>=100,\n",
    "        2: df['neutral_fat']>=np.log1p(200),\n",
    "        3: (df['hdl']<40)|(df['ldl']>=160),\n",
    "        4: (df['got']>np.log1p(40))|(df['gpt']>np.log1p(40)),\n",
    "        5: df['hemoglobin']+df['gender']<=13, #modified from <13\n",
    "        6: (df['max_bp']>=130)|(df['min_bp']>=80)\n",
    "    }\n",
    "\n",
    "    diseases = np.where(criterion[disease_no], 1, 0)\n",
    "    diseases = pd.Series(diseases, index=df.index)\n",
    "\n",
    "    #Leaving lifelog and servey.etc\n",
    "    #df = df[df.columns[19:].append(pd.Index(target_variables[disease_no]))]\n",
    "    \n",
    "    x = df.copy()\n",
    "    x.drop(columns=target_variables[disease_no], axis=1, inplace=True)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, diseases, test_size=test_size, stratify=diseases)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline():\n",
    "    pca_for_features = ColumnTransformer([\n",
    "        ('pca_smoking_all', PCA(n_components=1), ['have_smoking', 'smoking_duration_all', 'smoking_all_count']),\n",
    "        ('pca_secondary_smoking_home', PCA(n_components=1), ['secondary_smoking_home', 'secondary_smoking_home_count_per_week', 'secondary_smoking_duration_home', 'secondary_smoking_hour_home']),\n",
    "        ('pca_secondary_smoking_work', PCA(n_components=1), ['secondary_smoking_work', 'secondary_smoking_work_per_week', 'secondary_smoking_duration_work', 'secondary_smoking_hour_work']),\n",
    "        ('pca_recent_symptom', PCA(n_components=2), ['last2week_symptom_decreasedintertest_in_last2weeks', 'last2week_symptom_depressed_in_last2weeks',\n",
    "                                                    'last2week_symptom_sleepdisorder_in_last2weeks', 'last2week_symptom_tiredness_in_last2weeks',\n",
    "                                                    'last2week_symptom_eatingdisorder_in_last2weeks', 'last2week_symptom_discourage_in_last2weeks',\n",
    "                                                    'last2week_symptom_decreasedconcentration_in_last2weeks', 'last2week_symptom_anxious_in_last2weeks',\n",
    "                                                    'last2week_symptom_selfharm_in_last2weeks'])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    lgbm_params = {\n",
    "        'learning_rate': [0.005, 0.01],\n",
    "        'n_estimators': [8,16,24],\n",
    "        'num_leaves': [6,8,12], # large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "        'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n",
    "        'objective' : ['binary'],\n",
    "        'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progress\n",
    "        'random_state' : [500],\n",
    "        'colsample_bytree' : [0.64, 0.65, 0.66],\n",
    "        'subsample' : [0.7,0.75],\n",
    "        'reg_alpha' : [1,1.2],\n",
    "        'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "    LGBMClassifier.transform = lambda self,x:x\n",
    "\n",
    "    main_pipeline = Pipeline([\n",
    "        ('imputer', IterativeImputer()),\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('pca_for_smoking', pca_for_features),\n",
    "        ('estimator', GridSearchCV(estimator=LGBMClassifier(), param_grid=lgbm_params, cv=KFold(n_splits=5, shuffle=True), n_jobs=-3))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return main_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_test, y_predproba, random_state, criteria=0.5):\n",
    "    y_pred = y_predproba[:,1] >= criteria\n",
    "\n",
    "    score_df = pd.DataFrame()\n",
    "    #TODO: confusion matrix\n",
    "    score_df['accuracy'] = [accuracy_score(y_test, y_pred)]\n",
    "    score_df['precision'] = [precision_score(y_test, y_pred)]\n",
    "    score_df['recall'] = [recall_score(y_test, y_pred)]\n",
    "    score_df['f1_score'] = [f1_score(y_test, y_pred)]\n",
    "    score_df['auroc'] = [roc_auc_score(y_test, y_predproba[:,1])]\n",
    "    score_df['auprc'] = [average_precision_score(y_test, y_predproba[:,1])]\n",
    "\n",
    "    score_df.index = ['experiment' + str(random_state)]\n",
    "\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featimp(main_pipeline, x_test, random_state):\n",
    "    transformed_x_test = main_pipeline.transform(x_test)\n",
    "\n",
    "    explainer = shap.TreeExplainer(main_pipeline['estimator'].best_estimator_)\n",
    "    shap_values = explainer.shap_values(transformed_x_test)\n",
    "\n",
    "    vals= np.abs(shap_values[1]).mean(0)\n",
    "    shap_importance = pd.DataFrame([vals], index=['shap_value'+ str(random_state)], columns=main_pipeline.transform(x_test).columns)\n",
    "    \n",
    "    return shap_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(file_lists):\n",
    "    for df, name in file_lists:\n",
    "        if not os.path.exists(name):\n",
    "            df.to_csv(name, index=True, mode='w', encoding='utf-8-sig')\n",
    "        else:\n",
    "            df.to_csv(name, index=True, mode='a', encoding='utf-8-sig', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(disease_no, score_file_name, featimp_file_name, random_state=0):\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = load_dataset(disease_no=disease_no)\n",
    "    main_pipeline = build_pipeline()\n",
    "\n",
    "    weight = class_weight.compute_sample_weight('balanced', y_train)\n",
    "\n",
    "    main_pipeline.fit_transform(x_train, y_train, **{'estimator__sample_weight': weight})\n",
    "    y_predproba = main_pipeline.predict_proba(x_test)\n",
    "\n",
    "    score_df = scoring(y_test, y_predproba, random_state)\n",
    "    featimp_df = featimp(main_pipeline, x_test, random_state)\n",
    "\n",
    "    export_to_csv([(score_df, score_file_name), (featimp_df, featimp_file_name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(disease_no, path = 'Outputs/tmp', random_state_list = range(0, 10)):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    for random_state in random_state_list:\n",
    "        print(\"Current training: Disease {}, random state: {}\".format(disease_no, random_state))\n",
    "        train(disease_no, score_file_name=path + '/' + str(disease_no) + '_eval.csv', featimp_file_name=path + '/' + str(disease_no) + '_featimp.csv', random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current training: Disease 0, random state: 0\n",
      "Current training: Disease 0, random state: 1\n",
      "Current training: Disease 0, random state: 2\n",
      "Current training: Disease 0, random state: 3\n",
      "Current training: Disease 0, random state: 4\n",
      "Current training: Disease 0, random state: 5\n",
      "Current training: Disease 0, random state: 6\n",
      "Current training: Disease 0, random state: 7\n",
      "Current training: Disease 0, random state: 8\n",
      "Current training: Disease 0, random state: 9\n",
      "Current training: Disease 1, random state: 0\n",
      "Current training: Disease 1, random state: 1\n",
      "Current training: Disease 1, random state: 2\n",
      "Current training: Disease 1, random state: 3\n",
      "Current training: Disease 1, random state: 4\n",
      "Current training: Disease 1, random state: 5\n",
      "Current training: Disease 1, random state: 6\n",
      "Current training: Disease 1, random state: 7\n",
      "Current training: Disease 1, random state: 8\n",
      "Current training: Disease 1, random state: 9\n",
      "Current training: Disease 2, random state: 0\n",
      "Current training: Disease 2, random state: 1\n",
      "Current training: Disease 2, random state: 2\n",
      "Current training: Disease 2, random state: 3\n",
      "Current training: Disease 2, random state: 4\n",
      "Current training: Disease 2, random state: 5\n",
      "Current training: Disease 2, random state: 6\n",
      "Current training: Disease 2, random state: 7\n",
      "Current training: Disease 2, random state: 8\n",
      "Current training: Disease 2, random state: 9\n",
      "Current training: Disease 3, random state: 0\n",
      "Current training: Disease 3, random state: 1\n",
      "Current training: Disease 3, random state: 2\n",
      "Current training: Disease 3, random state: 3\n",
      "Current training: Disease 3, random state: 4\n",
      "Current training: Disease 3, random state: 5\n",
      "Current training: Disease 3, random state: 6\n",
      "Current training: Disease 3, random state: 7\n",
      "Current training: Disease 3, random state: 8\n",
      "Current training: Disease 3, random state: 9\n",
      "Current training: Disease 4, random state: 0\n",
      "Current training: Disease 4, random state: 1\n",
      "Current training: Disease 4, random state: 2\n",
      "Current training: Disease 4, random state: 3\n",
      "Current training: Disease 4, random state: 4\n",
      "Current training: Disease 4, random state: 5\n",
      "Current training: Disease 4, random state: 6\n",
      "Current training: Disease 4, random state: 7\n",
      "Current training: Disease 4, random state: 8\n",
      "Current training: Disease 4, random state: 9\n",
      "Current training: Disease 5, random state: 0\n",
      "Current training: Disease 5, random state: 1\n",
      "Current training: Disease 5, random state: 2\n",
      "Current training: Disease 5, random state: 3\n",
      "Current training: Disease 5, random state: 4\n",
      "Current training: Disease 5, random state: 5\n",
      "Current training: Disease 5, random state: 6\n",
      "Current training: Disease 5, random state: 7\n",
      "Current training: Disease 5, random state: 8\n",
      "Current training: Disease 5, random state: 9\n",
      "Current training: Disease 6, random state: 0\n",
      "Current training: Disease 6, random state: 1\n",
      "Current training: Disease 6, random state: 2\n",
      "Current training: Disease 6, random state: 3\n",
      "Current training: Disease 6, random state: 4\n",
      "Current training: Disease 6, random state: 5\n",
      "Current training: Disease 6, random state: 6\n",
      "Current training: Disease 6, random state: 7\n",
      "Current training: Disease 6, random state: 8\n",
      "Current training: Disease 6, random state: 9\n"
     ]
    }
   ],
   "source": [
    "for num in range(0, 7):\n",
    "    main(num, path='Outputs/without_healthcheck')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
